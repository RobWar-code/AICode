Worked Examples and Strategies

Contents
    Status Reports
        Status May 2025
    Problem Space Background
        Review of Methodology
            Further Detailed Analysis
        Analysis of Code Scoring
        Code Entrapments
        Approaches to Code Development
    Ruleset Strategies
        Selecting Rules
            Combining Rules
        Analytical Code
        Code Fragment Candidates
        General Approaches
        Possible Future Approaches
            Staged Introduction of Rules
            Allow What Evolves and Pick the Useful
            Selecting Marked Sections
        valuesSet
        valuesOutMatchInputParams
    Reduced Instruction Set Considerations
    AI Code - Example Sequences
    Toward Stepped Rules
        Setting Up Tests to Derive Further Instruction Sequences
    Toward Stepped Pathways
    Favouring Seed Rules - Seed Beds
    Short Sampling
    Static Templates
    Solution Mesh Analogy
    Performance Notes

<h1>Status Reports

<h2>Status May 2025
    The system as it stands has completed all bar the final 3 of the rules, 
    requiring seed programs in about 7 cases out of 60. Although the system
    completed the first ASCII rule, it seems likely that subsequent rules
    will need seed intervention, and this begins to beg the question of
    what the system is for.

<h1>Problem Space Background
    Using the instruction set to date, we can consider the solution to
    the first three rules. When written by hand, this requires about 57
    bytes of code, arranged in a particular order. Since there are
    currently 56 possible instructions, the raw probability of this code
    56 ^ 57, an astronomical number. Even if we retain an instruction at
    each pass for this solution, we would have
        S = (x ^ (n + 1) - 1) / (x - 1)
        S = ((56 ^ 58) - 1) / 55

    Nevertheless, out of this probability space, "solutions" emerge. The
    wider we make our problem space (number of rules in ruleset), the greater 
    the chances of forms of "hit".

    If solutions typically consume 60 bytes, then the storage space of
    256 bytes provides for only 4 optimal solutions. This also explains
    why the system tends to go for scattered numbers and series rather
    than focusing on specific solutions. In effect, we are evolving an optimal
    number scattering solution, rather than specific solutions, although 
    specific solutions may arise incidentally.

    So, turning the issue on its head, we can allow the entities to explore
    the problem space(s) and seek to optimise the delivery times and incidence
    of "useful" solutions.

    Within this framework, we have to allow for the fact that only one or
    two specific solutions are likely to arise, along with the general solution
    in the 256 byte space. We can solve this in two ways. Either by extending
    the size of the memory space for each entity (which further widens the 
    probability space) or by expanding the number of entities so that they form
    separate territories, which may specialise in different problems.

    We note that number scattering is likely to be a very different solution
    to specific solutions, other than in the deployment of loops for series.

<h2>Review of Methodology
    15/03/2025

    To summarise the approach of the evolutionary method for problem solving
    that is currently deployed, we can say that we are providing inputs that
    must be matched to outputs using coincidental code sequences that are
    scored depending on the match to the required outputs. Code sequences
    are manipulated by various mutation methods and it is hoped that a score
    incremental sequence of events gives rise to an adequate solution.

    This approach is weak in the sense that coincidental matches to the
    output requirements that score in the mid-range, may in fact require
    lower probability adjustments to attain the solution than other
    code sequences that could be used to approach the solution. This is basically
    because the code sequences are both order and detail critical.

    There is currently no "intelligence" in the ordering or selection of 
    instructions for the code sequences.

    It is currently hoped that by using successful and hand-written solutions
    from a pool, more successful modification pathways can be found by the
    random approach in the tackling of novel problems.

    However, we note that the more sequences that there are in the pool, the lower
    the probability of finding a useful prior sequence there will be.

    The basic question behind this is: Can the system solve a general range of problems
    without prior knowledge or bias?

<h3>Further Detailed Analysis

    Looking at the permutations/combinations of the instruction set,
    we have it that given arrangements of code have the following
    probabilities

    5 Instructions (2 data): 1/(56^5 + 256^2) = 1/(550,797,312)

    Given that this is the raw probability, let us assume that the
    monte carlo method is 50% efficient, so then the probability is
    
    1/(3 * 56 + 56^2 + 256^2) = 1/68840

    Consider 8 instructions with our variation of monte carlo:
    1/(5 * 56 + 56^3 + 256^3) = 1/(16,953,112)

    Assuming 3,000,000 trials per hour, we can see that an 8
    instruction modification is likely to take an average of
    about 2.5 hours.

    Clearly it is exponentially in our time interests to keep the number
    of modifications required from rule to rule to a minimum.

    This suggests small step and branch in our selection of rules.

<h2>Analysis of Code Scoring
    The advantage of having rule(s) that score the actual entity code
    is that they bear on the pathway to the solution and may suggest 
    solutions independently of the outputs. If, for example we have
    the solution to getNumbersGreaterThanFirst and are then seeking
    getNumbersLessThanFirst, we note that the code requirements for
    each are very similar, despite the outputs being so different.


<h2>Code Entrapments

    A problem that arises in the rule/score approach for code-based evolution
    is that code that scores well initially may require a very large probabilistic
    leap to move on to the next stage. This is advantage of gradated scoring, rather
    than flat hit and miss scoring. Of course, in this case it is the code
    sequences that we are looking for, even though we are testing for the output
    results.

    Let's try small code fragments that may help produce large leaps in code
    progress.

    We have to bear in mind that it is code "solutions" that we are looking for,
    rather than output results per se.

<h2>Approaches to Code Development

    The most likely approaches to the trialing and development of code
    that might be incorporated into a system are:
        Sequential Trials
        Random Trials
        Analytical Trials

    Or hybrids between these approaches.

    Sequential trials are generally not applicable because of the
    scale of code combinations and permutations.

    Random trials with scored performance and accumulated variations
    provides a means of exploring a very large probability space,
    although the time-scales involved may be very large.

        
<h1>Ruleset Strategies

<h2>Selecting Rules
    19/02/2025

    Having settled successfully on completing one rule at a time and
    using seed from this rules for each new rule, the question becomes
    what rules to select.

    The initial aim is for the system to learn to interpret and execute
    ASCII representations of arithmetic expressions, ie:
        "a + b;"
        "a / b;"

    The initial rules involve performing a single arithmetic operation
    on each of the input parameters.

    Then follow the rules for arranging adjacent parameters.

    Then follow the rules for performing arithmetic operations on adjacent
    parameters.

    Then follow the rules for performing arithmetic operations on adjacent
    parameters using an ASCII operator prompt.

    Then follow the rules for converting ASCII number strings 

    The next rule due is to supply ASCII arithmetic instructions
    on the input.

    The current trial extends as far as the previous rule and should
    be time tested for that purpose. (expected 4 to 5 days).

    The following rule is to perform ASCII arithmetic expressions.

<h3>Combining Rules
    Where we are attempting to combine solutions to specific instances
    the system can either concatenate the prior solutions using
    conditionals or rework the solutions into a simplified algorithm.
    Here we inspect both options.

    In the case of (two) concatenated solutions we need something like:

    LoopNext:
    LD A, (source value)
    LD B, (test value)
    CMP A, B
    JRZ Action2
    // Else 
    Do the first solution
    JR LoopNext
    Action2:
    JR LoopNext

    So we can see that this operation requires 6 instructions.
    We could reward the co-incidental combination
        LD A, (C)
        LD B, (IMM)
        CMP A,B
        JRZ

    Or we could include such useful combinations as standard
    potential inserts in the mutation/breed cycles. (code fragments)
    from the instruction set class.

<h2>Analytical Code

    The instruction set now includes the instructions:
        LDSI A - load sample input byte
        LDSO A - load sample output byte
        LSIL A - load sample input length
        LSOL A - load sample output length
        LDIL A - load input length
        LDOL A - load output length

    In order to encourage analytical entity code that may
    reduce the time required to produce solutions, we might
    have a helper rule that tests for the presence of these
    instructions, or we might have a principle rule that
    scores the use of these, or both.

    Examples of example data rules might be output: 
        example input > example output
        example input - example output

    The code from these rules might then merge successfully
    with later rules.

<h2>Code Fragment Candidates

    General purpose double loops are likely to be useful, consider:

    [
        {
            ins: "LD A, IMM",
            data: [16]
        },
        {
            label: "mainloop",
            ins: "PUSH A"
        },
        {
            ins: "LD B, IMM",
            data: [0]
        },
        {
            ins: "PUSH B"
        },
        {
            label: "innerloop",
            freeform: 12
        },
        {
            ins: "POP B"
        }
        {
            ins: "DEC B"
        },
        {
            ins: "JRNZ",
            data: [0xF2] // innerloop
        },
        {
            ins: "POP A",
        },
        {
            ins: "DEC A",
        },
        {
            ins: "JRNZ",
            data: [0xE7] // mainloop
        }
    ]



<h2>General Approaches
    Step 1) Put values in the output
    Step 2) Read the input and place in the output
    Step 3) Read the input and put a value at the specified memory location
    Step 4) Put a series in the output
    Step 6) Read the input and modify in a simple way (eg: +3)
    Step 6a) input -3
    Step 6b) input *2
    Step 6c) input /2
    Step 7) Cued inputs with parameters, ie = 100(addr) 10, + 5 6, * 2 7

    In practice even after 20,000,000 or so trials, the system
    devolves to distributing arrangements of random numbers and 
    series in a scatter through the output area. Although the 
    introduction of breeding ranges and a output difference test
    for each execution cycle has improved the rate of change.
    There is a marked absence of systematic manipulation of the
    inputs. This might be improved by balancing the input 
    instruction distribution in favour of LDI operations. Even
    direct transfer of inputs to the output fails when tied to
    a non-zero based output block.

<h3>Considerations for rule scoring
    On the one hand more valuable or lower pobability/higher complexity
    outputs should score more. However, this means that correct, lower
    scoring results may be overwritten by chance byte values having been
    set in the output. A possible solution to this is to add a bonus for
    a complete solution and to keep score weightings relatively flat.

<h2>Possible Future Approaches

<h3>Staged Introduction of Rules
    This would involve stepping through the rules after specific
    numbers of cycles. This may encourage more concentration on 
    specific solutions and help to establish the IPO habit.

    However code patterns may well degrade to random scatter as
    new rules are introduced.

    This approach was added, without significant improvement.
    Although a trial is now underway which shows some promise
    with the stages extended somewhat.

<h3>Allow What Evolves and Pick the Useful
    This approach modifies the user demands of the system, to
    one of producing interesting or useful code fragments and
    sections over an open-ended period of time.

    This approach would allow the opportunistic addition of rules
    to favour certain patterns of output, so that after a medium
    period of time, certain interesting effects would begin to
    arise.

    In this case the addition of rules to the system over time 
    should be allowed for.

    This may well require substantial development to facilitate 
    user intervention and observation.

<h3>Selecting Marked Sections

    A possible approach to heirarchical selection of code is
    to pick-out code sections that are actually used by the
    entity. As the instructions run, the code can be flagged
    at the instruction positions. Subsequently, the marked
    blocks can be extracted and combined to make a new entity.

    The main difficulty with this approach is deciding how best
    to combine and make use of the sections. One possibility
    is to wrap them in SM, RET instructions and call them
    from the head of the code. Another is simply to cross-breed
    with the flagged blocks and rely on mutations to merge
    the code together.

    This approach set-up and current trial seems to produce
    some improvements.

<h2>valuesSet
    Since the primary aim is to produce out, the first rule
    is valuesSet this checks each byte of the output to see
    if a non-zero value has been set. The score is a factor
    of 1 per byte set over the tested range.

    A typical sequence of entity code required to get the 
    maximum for this rule would be:

    INC A
    STO (C), A
    INC C
    JR [0xFD]

<h2>valuesOutMatchInputParams
    This is tested for in a specific block of 8 bytes and
    specific set of input parameters, so not only must the
    operating entity discover the necessary output, but also
    the specific inputs.

<h1>AI Code - Example Sequences

1) Sequence of numbers from output position 0
    INC A                           1/56
    STO (C), A                      1/56
    INC C                           1/56
    JR 0xFD (or lower)              1/(56 * (256 - (127 - 2)))

1A) Example from AI Code
    DEC B               B:255        B:1            B:254
    STO (C), A          O(0):0       O(255):0       O(2):255
    INC A               A:1          A:1            A:0
    INC A               A:2          A:2            A:1
    SWP A, C            A:0, C:2     A: 255:, C:2   A:2, C: 1
    SWP B, C            B:2, C:255   C:1, B:255     B:1, C:254
    JR 0x8E

<h1>Toward Stepped Rules
As at 08/02/2025 The following rules have been successfully
matched:
0) output matches initial params
1) params plus six
2) params minus six
3) params times two
4) add first param
5) add second param
6) duplicate params
7) skip adjacent params 1
8) skip adjacent params 2
9) swap adjacent params
10) greater of adjacent params
11) sort adjacent params
12) add adjacent params - stuck trying this rule

The idea is that each rule leads to another by the overcoming
of a probabilistic hurdle, such as adding three instructions.
Hurdles should not be too high (generally not more than three
or four instructions).

Part of the problem is that a higher score does not necessarily
mean greater proximity, in instruction terms, to the required
result. But it is hard to see, if we avoid foreknowledge, how
we can avoid this.


As at 04/02/2025, the system now issues rules in a predefined
sequence. The following rules have been successful:
0) output matches initial params
1) params plus three
2) params minus three
3) params times two
4) skip adjacent params 1
5) skip adjacent params 2 (variable without 4))
6) swap adjacent params

Let's look at the basic code requirements for each (in practice versions of these with 
redundancy are also possible):

0) output matches initial params
    LDI A, (C)
    STO (C), A
    INC C
    JR [0xFD or less]

Arithmetic

1) params plus 3
    LD B, IMM [3]
    LDI A, (C)
    ADD A, B
    STO (C), A
    INC C
    JR [0xFC or less]

2) params minus 3
    LD B, IMM [3]
    LDI A, (C)
    SUB A, B
    STO (C), A
    INC C
    JR [0xFC or less]

3) params times 2
    LDI A, (C)
    SWP A, B
    LDI A, (C)
    ADD A,B
    STO (C), A
    INC C
    JR [0xFA or less]

Memory Arrangement

4) skip adjacent params 1 - variants of this are also possible using memory locations rather than the stack.
    LD C, IMM [0]
    PUSH C
    POP (C)
    LDI A, (C)
    INC C
    INC C
    PUSH C
    SWP B, C
    STO (C), A
    INC C
    SWP B, C
    JR [0xF7]

5) skip adjacent params 2
    LD C, IMM [0]
    INC C
    PUSH C
    POP (C)
    LDI A, (C)
    INC C
    INC C
    PUSH C
    SWP B, C
    STO (C), A
    INC C
    SWP B, C
    JR [0xF7]

<h2>Setting Up Tests to Derive Further Instruction Sequences
    
Can some simpler memory arrangement steps be designed? The aim
should be that no rule should take longer than about 2 hours
(about 40 rounds).

Consider repeat input params

    PUSH C
    POP C
    LDI A, C
    INC C
    PUSH C
    SWP B, C
    STO (C), A
    INC C
    STO (C), A
    INC C
    SWP B, C
    JR [0xF6]
    
<h1>Toward Stepped Pathways
    Having tested the app as at 05/12/2025 - we find that code
    entities plateau with a score of about 1/3 of the maximum
    using a mixture of random number and series transfers to
    output, but also a degree of reading from the input.

    These scores were achieved after about 80 million trials
    and scoring progress was very slow indeed at this point.

    The most likely account for this is that further improvement
    would require very low probability events in the breed/mutate
    cycle.

    Here, we consider stepped pathways, in which no progressive
    step has a probability lower than a certain threshold.

    So let us consider some sequences.

    Firstly consider

    LDI A, (C) // LD A from the input buffer
    STO (C), A // ST A in the output buffer
    INC C 
    JR 0xFC // Jump relative back to start

    Using the rule sets, this scores on valuesOutSet, valuesFromInitialParams and various random
    hits as the input fills the output.

    However this does not approach solving the individual problems in the ruleset.

    Consider:

    LD B, IMM 8
    Loop:
    PUSH B
    LDI A, (C)
    LD B, IMM 3
    ADD A, B
    STO (C), A
    POP B
    DEC B
    JRZ 2
    JR 0xF7 (Loop)

    Which is the solution for rule paramsPlusThree. How could the system arrive at this solution
    by stepwise enhancements?

    One possibility is to score particular sequences of instructions which might be useful, for example
    LDI A, (C)
    LD B, IMM
    ADD A, B
    STO (C), A

    This has the disadvantage of requiring some foreknowledge about the type and form of problems to
    be solved.

<h2>Further Ideas on Stepped Pathways

    When considering how the system approaches the solution to the rules, we can consider the
    case in which an entity obtains a single hit on a required output, this might or might
    not be derived from an input(s).

    Having obtained one or a few matched outputs, the system has the problem of assembling
    the required loop controls, whether from the inputs or by crude guess.

    Does the existing fragment system allow for this stepping of scores?

<h1>Favouring Seed Rules - Seed Beds

    Whilst seed rules from existing solutions may be more useful than random code
    in solving the current rule, unless their outputs coincidentally match the
    required outputs, they are unlikely to do better than random code on the score
    and select basis.

    To obviate the problem of limited seed-rule success it may be useful to establish
    seed-bed sets (say 8 * 4 = 32 best sets), that only accept a seed program as the
    originator of entity programs. These can be allowed to run, possibly for 60 rounds
    to see if they achieve 80% of the target, at which point they can be replaced by
    other seed if not. Once the 80% target has been the best entities can be seeded
    into the rest of the best set (4 * 10 = 40 best sets).

    For further notes on this, consult the README documentation and notes.txt

<h1>Short Sampling
    Rather than playing-out individual rules to cycle to success or failure,
    we might use a shorter cycle time per rule (say 8 rounds) to derive the best
    score. If after 8 rounds, a pass is reached, then this is saved as seed,
    otherwise the best scoring program is stashed as potential material for
    use in the solving of other rules.

    Such an approach might encourage the evolution of natural template-type
    sequences.

<h2>Implementation
    Set the maximum cycles for a rule to about 8.
    Save the highest scoring program in the new "bestsStore" (this also requires
    file system storage).
    When code is bred, have an option to select the entity code from the bestsStore,
    say probability slightly higher than seed programs or templates.
    We also need to change the clearance cycle.

<h1>Static Templates
    If we use specific template manipulation procedures rather than the usual
    breed methods, we can increase the probability of particular code permutations
    being found, within the scope of the template.

    However, if we use manual templates, then likely, intermediate scores will
    be unlikely and we are faced with the absolute probability of the working
    combination being derived, rather than being able to evolve through
    gradations.
    
<h1>Solution Mesh Analogy
    If we liken each accumulated solution to a node in a mesh and the joining fibres to
    the probabilistic transition from node to node, then we can see that we
    should:

    a) Make code-related rules
    b) Have as wide a set of rules as practical
    c) Possibly design ways to relate old rules to new rules

<h1>Performance Notes

    25/01/2025
    Reduced cross-set breed chance to 0.001 to increase diversity on main computer.

    Best Score: 56.5636
    Loops: Long stretch (44 bytes) with multiple outputs, trailed by a closing loop producing
        output sequences of about 10 bytes.
    Elapsed Time: 1.8105
    Number of Trials: 6,048,000
    Comments: More varied best set results

    24/01/2025
    Trial on main computer, adjusted clearance pass to 10 rounds

    Best Score: 61.1617
    Loops: Two overlapping loops reading the input and assigning to the output
        with a couple of bytes set with immediate values. Total executed sequence
        is 33 bytes.
    Elapsed Time: 18.8172
    Number of Trials: 57,184,000
    Comments: There seems little gain from the modification of the clearance pass

    Best Score: 55.2929
    Loops: First loop to set the initial parameters, second to add incrementing
        set of numbers
    Elapsed Time: 3.0535
    Number of Trials: 9,792,000

    24/01/2025
    Generalisation of byte scores

    Best Set Score: 64.924
    Loops: Long double loop with a short tail loop with jump back to out-of sequence
        instruction
    Elapsed Time: 22.9824
    Number of Trials: 129,420,800
    Comments: Locked into the same pattern for a long time

    Best Set Score: 61.2908
    Loops: Long double loop with a short tail loop with jump back to out-of sequence
        instruction
    Elapsed Time: 5.651
    Number of Trials: 32,486,400

    Best Set Score: 58.8769
    Loops: Two loops, the first being invoked with a CASM and RET, the second with
        a JR.
    Elapsed Time: 2.6263
    Number of Trials: 16,172,800

    23/01/2025
    Addition of convert ASCII numbers rule

    Best Set Score: 57.7241 from 162
    Loops: As previous, but also included a send conditional jump back which may activate
    Elapsed Time: 9.2121
    Number of Trials: 51,014,400

    Best Set Score: 56.4711 from 162
    Loops: 2 Loops, the first with a conditional branch which jumps to the second
    Elapsed Time: 2.1539
    Number of Trials: 12,550,400

    22/01/2025
    Add clearance of duplicated outputs

    Best Set Score: 61.6447 from 154
    Loops: 2 loops, both modified by themselves
    Elapsed Time: 18.6437
    Number of Trials: 85,017,600
    Comments: Quite a bit faster improvement than the previous 30,000,000 trials.

    Best Set Score: 59.8913
    Loops: 2 Self-modifying loops
    Elapsed Time: 11.5534
    Number of Trials: 51,488,000
    Comments: Note that it has taken 6 hours to gain 0.6 points.

    Best Set Score: 59.2335 from 146
    Loops: 3 self-modifying loops, bytes 0 - 47
    Elapsed Time: 5.5057
    Number of Trials: 21,740,800

    20 - 22/01/2025
    Best Set Score: 65.7074 from 146
    Loops: 2
    Loop Lengths: 12, 11
    Elapsed Time: 2.25 Days
    Number of Trials: 272,761,600

<h1>Reduced Instruction Set Considerations

    In order to reduced the scale of the probability field for
    the simpler rules, it may be useful to provide reduced
    instructions sets. This could managed by having lists of
    instruction codes to select from with the random breeding
    code insertions.

    If we assume a choice between a single list and the full
    set, we can allow the choice to made on the menu options.

    Suggested candidates for exclusion might be
        CFAR
        SM
        LISC A
        CALL
        RET
        CASM
        POP B 
        PUSH B 
        POP C 
        PUSH C 
        DEC SP 
        INC SP 
        JRLZ
        JRLC

    This would reduce number of selected instructions from 63 to 49.
    If we allow for multiple lists, we can compare performances for
    different ranges of instructions.

<h2> High Probability Branching and Memory Locations

    We could have a set of say 8 fixed branch addresses
    and use a special instruction to access them.
    Say JRS n, where n is 0 to 8. We allow for a data
    restrictor in instruction set. Or possibly, we divide
    the data byte in the instruction code.

    We could have a block of memory that spans say 10
    locations and use a corresponding instruction.
