Worked Examples and Strategies

Contents
    Status Reports
        Status May 2025
    Problem Space Background
        Review of Methodology
            Further Detailed Analysis
        Analysis of Code Scoring
        Code Entrapments
        Approaches to Code Development
    Ruleset Strategies
        Selecting Rules
            Combining Rules
        Analytical Code
        Code Fragment Candidates
        General Approaches
        Possible Future Approaches
            Staged Introduction of Rules
            Allow What Evolves and Pick the Useful
            Selecting Marked Sections
        valuesSet
        valuesOutMatchInputParams

    AI Code - Example Sequences
    Toward Stepped Rules
        Setting Up Tests to Derive Further Instruction Sequences
    Toward Stepped Pathways
    Performance Notes

<h1>Status Reports

<h2>Status May 2025
    The system as it stands has completed all bar the final 3 of the rules, 
    requiring seed programs in about 7 cases out of 60. Although the system
    completed the first ASCII rule, it seems likely that subsequent rules
    will need seed intervention, and this begins to beg the question of
    what the system is for.

<h1>Problem Space Background
    Using the instruction set to date, we can consider the solution to
    the first three rules. When written by hand, this requires about 57
    bytes of code, arranged in a particular order. Since there are
    currently 56 possible instructions, the raw probability of this code
    56 ^ 57, an astronomical number. Even if we retain an instruction at
    each pass for this solution, we would have
        S = (x ^ (n + 1) - 1) / (x - 1)
        S = ((56 ^ 58) - 1) / 55

    Nevertheless, out of this probability space, "solutions" emerge. The
    wider we make our problem space (number of rules in ruleset), the greater 
    the chances of forms of "hit".

    If solutions typically consume 60 bytes, then the storage space of
    256 bytes provides for only 4 optimal solutions. This also explains
    why the system tends to go for scattered numbers and series rather
    than focusing on specific solutions. In effect, we are evolving an optimal
    number scattering solution, rather than specific solutions, although 
    specific solutions may arise incidentally.

    So, turning the issue on its head, we can allow the entities to explore
    the problem space(s) and seek to optimise the delivery times and incidence
    of "useful" solutions.

    Within this framework, we have to allow for the fact that only one or
    two specific solutions are likely to arise, along with the general solution
    in the 256 byte space. We can solve this in two ways. Either by extending
    the size of the memory space for each entity (which further widens the 
    probability space) or by expanding the number of entities so that they form
    separate territories, which may specialise in different problems.

    We note that number scattering is likely to be a very different solution
    to specific solutions, other than in the deployment of loops for series.

<h2>Review of Methodology
    15/03/2025

    To summarise the approach of the evolutionary method for problem solving
    that is currently deployed, we can say that we are providing inputs that
    must be matched to outputs using coincidental code sequences that are
    scored depending on the match to the required outputs. Code sequences
    are manipulated by various mutation methods and it is hoped that a score
    incremental sequence of events gives rise to an adequate solution.

    This approach is weak in the sense that coincidental matches to the
    output requirements that score in the mid-range, may in fact require
    lower probability adjustments to attain the solution than other
    code sequences that could be used to approach the solution. This is basically
    because the code sequences are both order and detail critical.

    There is currently no "intelligence" in the ordering or selection of 
    instructions for the code sequences.

    It is currently hoped that by using successful and hand-written solutions
    from a pool, more successful modification pathways can be found by the
    random approach in the tackling of novel problems.

    However, we note that the more sequences that there are in the pool, the lower
    the probability of finding a useful prior sequence there will be.

    The basic question behind this is: Can the system solve a general range of problems
    without prior knowledge or bias?

<h3>Further Detailed Analysis

    Looking at the permutations/combinations of the instruction set,
    we have it that given arrangements of code have the following
    probabilities

    5 Instructions (2 data): 1/(56^5 + 256^2) = 1/(550,797,312)

    Given that this is the raw probability, let us assume that the
    monte carlo method is 50% efficient, so then the probability is
    
    1/(3 * 56 + 56^2 + 256^2) = 1/68840

    Consider 8 instructions with our variation of monte carlo:
    1/(5 * 56 + 56^3 + 256^3) = 1/(16,953,112)

    Assuming 3,000,000 trials per hour, we can see that an 8
    instruction modification is likely to take an average of
    about 2.5 hours.

    Clearly it is exponentially in our time interests to keep the number
    of modifications required from rule to rule to a minimum.

    This suggests small step and branch in our selection of rules.

<h2>Analysis of Code Scoring
    The advantage of having rule(s) that score the actual entity code
    is that they bear on the pathway to the solution and may suggest 
    solutions independently of the outputs. If, for example we have
    the solution to getNumbersGreaterThanFirst and are then seeking
    getNumbersLessThanFirst, we note that the code requirements for
    each are very similar, despite the outputs being so different.


<h2>Code Entrapments

    A problem that arises in the rule/score approach for code-based evolution
    is that code that scores well initially may require a very large probabilistic
    leap to move on to the next stage. This is advantage of gradated scoring, rather
    than flat hit and miss scoring. Of course, in this case it is the code
    sequences that we are looking for, even though we are testing for the output
    results.

    Let's try small code fragments that may help produce large leaps in code
    progress.

    We have to bear in mind that it is code "solutions" that we are looking for,
    rather than output results per se.

<h2>Approaches to Code Development

    The most likely approaches to the trialing and development of code
    that might be incorporated into a system are:
        Sequential Trials
        Random Trials
        Analytical Trials

    Or hybrids between these approaches.

    Sequential trials are generally not applicable because of the
    scale of code combinations and permutations.

    Random trials with scored performance and accumulated variations
    provides a means of exploring a very large probability space,
    although the time-scales involved may be very large.

        
<h1>Ruleset Strategies

<h2>Selecting Rules
    19/02/2025

    Having settled successfully on completing one rule at a time and
    using seed from this rules for each new rule, the question becomes
    what rules to select.

    The initial aim is for the system to learn to interpret and execute
    ASCII representations of arithmetic expressions, ie:
        "a + b;"
        "a / b;"

    The initial rules involve performing a single arithmetic operation
    on each of the input parameters.

    Then follow the rules for arranging adjacent parameters.

    Then follow the rules for performing arithmetic operations on adjacent
    parameters.

    Then follow the rules for performing arithmetic operations on adjacent
    parameters using an ASCII operator prompt.

    Then follow the rules for converting ASCII number strings 

    The next rule due is to supply ASCII arithmetic instructions
    on the input.

    The current trial extends as far as the previous rule and should
    be time tested for that purpose. (expected 4 to 5 days).

    The following rule is to perform ASCII arithmetic expressions.

<h3>Combining Rules
    Where we are attempting to combine solutions to specific instances
    the system can either concatenate the prior solutions using
    conditionals or rework the solutions into a simplified algorithm.
    Here we inspect both options.

    In the case of (two) concatenated solutions we need something like:

    LoopNext:
    LD A, (source value)
    LD B, (test value)
    CMP A, B
    JRZ Action2
    // Else 
    Do the first solution
    JR LoopNext
    Action2:
    JR LoopNext

    So we can see that this operation requires 6 instructions.
    We could reward the co-incidental combination
        LD A, (C)
        LD B, (IMM)
        CMP A,B
        JRZ

    Or we could include such useful combinations as standard
    potential inserts in the mutation/breed cycles. (code fragments)
    from the instruction set class.

<h2>Analytical Code

    The instruction set now includes the instructions:
        LDSI A - load sample input byte
        LDSO A - load sample output byte
        LSIL A - load sample input length
        LSOL A - load sample output length
        LDIL A - load input length
        LDOL A - load output length

    In order to encourage analytical entity code that may
    reduce the time required to produce solutions, we might
    have a helper rule that tests for the presence of these
    instructions, or we might have a principle rule that
    scores the use of these, or both.

    Examples of example data rules might be output: 
        example input > example output
        example input - example output

    The code from these rules might then merge successfully
    with later rules.

<h2>Code Fragment Candidates

    General purpose double loops are likely to be useful, consider:

    [
        {
            ins: "LD A, IMM",
            data: [16]
        },
        {
            label: "mainloop",
            ins: "PUSH A"
        },
        {
            ins: "LD B, IMM",
            data: [0]
        },
        {
            ins: "PUSH B"
        },
        {
            label: "innerloop",
            freeform: 12
        },
        {
            ins: "POP B"
        }
        {
            ins: "DEC B"
        },
        {
            ins: "JRNZ",
            data: [0xF2] // innerloop
        },
        {
            ins: "POP A",
        },
        {
            ins: "DEC A",
        },
        {
            ins: "JRNZ",
            data: [0xE7] // mainloop
        }
    ]



<h2>General Approaches
    Step 1) Put values in the output
    Step 2) Read the input and place in the output
    Step 3) Read the input and put a value at the specified memory location
    Step 4) Put a series in the output
    Step 6) Read the input and modify in a simple way (eg: +3)
    Step 6a) input -3
    Step 6b) input *2
    Step 6c) input /2
    Step 7) Cued inputs with parameters, ie = 100(addr) 10, + 5 6, * 2 7

    In practice even after 20,000,000 or so trials, the system
    devolves to distributing arrangements of random numbers and 
    series in a scatter through the output area. Although the 
    introduction of breeding ranges and a output difference test
    for each execution cycle has improved the rate of change.
    There is a marked absence of systematic manipulation of the
    inputs. This might be improved by balancing the input 
    instruction distribution in favour of LDI operations. Even
    direct transfer of inputs to the output fails when tied to
    a non-zero based output block.

<h3>Considerations for rule scoring
    On the one hand more valuable or lower pobability/higher complexity
    outputs should score more. However, this means that correct, lower
    scoring results may be overwritten by chance byte values having been
    set in the output. A possible solution to this is to add a bonus for
    a complete solution and to keep score weightings relatively flat.

<h2>Possible Future Approaches

<h3>Staged Introduction of Rules
    This would involve stepping through the rules after specific
    numbers of cycles. This may encourage more concentration on 
    specific solutions and help to establish the IPO habit.

    However code patterns may well degrade to random scatter as
    new rules are introduced.

    This approach was added, without significant improvement.
    Although a trial is now underway which shows some promise
    with the stages extended somewhat.

<h3>Allow What Evolves and Pick the Useful
    This approach modifies the user demands of the system, to
    one of producing interesting or useful code fragments and
    sections over an open-ended period of time.

    This approach would allow the opportunistic addition of rules
    to favour certain patterns of output, so that after a medium
    period of time, certain interesting effects would begin to
    arise.

    In this case the addition of rules to the system over time 
    should be allowed for.

    This may well require substantial development to facilitate 
    user intervention and observation.

<h3>Selecting Marked Sections

    A possible approach to heirarchical selection of code is
    to pick-out code sections that are actually used by the
    entity. As the instructions run, the code can be flagged
    at the instruction positions. Subsequently, the marked
    blocks can be extracted and combined to make a new entity.

    The main difficulty with this approach is deciding how best
    to combine and make use of the sections. One possibility
    is to wrap them in SM, RET instructions and call them
    from the head of the code. Another is simply to cross-breed
    with the flagged blocks and rely on mutations to merge
    the code together.

    This approach set-up and current trial seems to produce
    some improvements.

<h2>valuesSet
    Since the primary aim is to produce out, the first rule
    is valuesSet this checks each byte of the output to see
    if a non-zero value has been set. The score is a factor
    of 1 per byte set over the tested range.

    A typical sequence of entity code required to get the 
    maximum for this rule would be:

    INC A
    STO (C), A
    INC C
    JR [0xFD]

<h2>valuesOutMatchInputParams
    This is tested for in a specific block of 8 bytes and
    specific set of input parameters, so not only must the
    operating entity discover the necessary output, but also
    the specific inputs.

<h1>AI Code - Example Sequences

1) Sequence of numbers from output position 0
    INC A                           1/56
    STO (C), A                      1/56
    INC C                           1/56
    JR 0xFD (or lower)              1/(56 * (256 - (127 - 2)))

1A) Example from AI Code
    DEC B               B:255        B:1            B:254
    STO (C), A          O(0):0       O(255):0       O(2):255
    INC A               A:1          A:1            A:0
    INC A               A:2          A:2            A:1
    SWP A, C            A:0, C:2     A: 255:, C:2   A:2, C: 1
    SWP B, C            B:2, C:255   C:1, B:255     B:1, C:254
    JR 0x8E

<h1>Toward Stepped Rules
As at 08/02/2025 The following rules have been successfully
matched:
0) output matches initial params
1) params plus six
2) params minus six
3) params times two
4) add first param
5) add second param
6) duplicate params
7) skip adjacent params 1
8) skip adjacent params 2
9) swap adjacent params
10) greater of adjacent params
11) sort adjacent params
12) add adjacent params - stuck trying this rule

The idea is that each rule leads to another by the overcoming
of a probabilistic hurdle, such as adding three instructions.
Hurdles should not be too high (generally not more than three
or four instructions).

Part of the problem is that a higher score does not necessarily
mean greater proximity, in instruction terms, to the required
result. But it is hard to see, if we avoid foreknowledge, how
we can avoid this.


As at 04/02/2025, the system now issues rules in a predefined
sequence. The following rules have been successful:
0) output matches initial params
1) params plus three
2) params minus three
3) params times two
4) skip adjacent params 1
5) skip adjacent params 2 (variable without 4))
6) swap adjacent params

Let's look at the basic code requirements for each (in practice versions of these with 
redundancy are also possible):

0) output matches initial params
    LDI A, (C)
    STO (C), A
    INC C
    JR [0xFD or less]

Arithmetic

1) params plus 3
    LD B, IMM [3]
    LDI A, (C)
    ADD A, B
    STO (C), A
    INC C
    JR [0xFC or less]

2) params minus 3
    LD B, IMM [3]
    LDI A, (C)
    SUB A, B
    STO (C), A
    INC C
    JR [0xFC or less]

3) params times 2
    LDI A, (C)
    SWP A, B
    LDI A, (C)
    ADD A,B
    STO (C), A
    INC C
    JR [0xFA or less]

Memory Arrangement

4) skip adjacent params 1 - variants of this are also possible using memory locations rather than the stack.
    LD C, IMM [0]
    PUSH C
    POP (C)
    LDI A, (C)
    INC C
    INC C
    PUSH C
    SWP B, C
    STO (C), A
    INC C
    SWP B, C
    JR [0xF7]

5) skip adjacent params 2
    LD C, IMM [0]
    INC C
    PUSH C
    POP (C)
    LDI A, (C)
    INC C
    INC C
    PUSH C
    SWP B, C
    STO (C), A
    INC C
    SWP B, C
    JR [0xF7]

<h2>Setting Up Tests to Derive Further Instruction Sequences
    
Can some simpler memory arrangement steps be designed? The aim
should be that no rule should take longer than about 2 hours
(about 40 rounds).

Consider repeat input params

    PUSH C
    POP C
    LDI A, C
    INC C
    PUSH C
    SWP B, C
    STO (C), A
    INC C
    STO (C), A
    INC C
    SWP B, C
    JR [0xF6]
    
<h1>Toward Stepped Pathways
Having tested the app as at 05/12/2025 - we find that code
entities plateau with a score of about 1/3 of the maximum
using a mixture of random number and series transfers to
output, but also a degree of reading from the input.

These scores were achieved after about 80 million trials
and scoring progress was very slow indeed at this point.

The most likely account for this is that further improvement
would require very low probability events in the breed/mutate
cycle.

Here, we consider stepped pathways, in which no progressive
step has a probability lower than a certain threshold.

So let us consider some sequences.

Firstly consider

LDI A, (C) // LD A from the input buffer
STO (C), A // ST A in the output buffer
INC C 
JR 0xFC // Jump relative back to start

Using the rule sets, this scores on valuesOutSet, valuesFromInitialParams and various random
hits as the input fills the output.

However this does not approach solving the individual problems in the ruleset.

Consider:

LD B, IMM 8
Loop:
PUSH B
LDI A, (C)
LD B, IMM 3
ADD A, B
STO (C), A
POP B
DEC B
JRZ 2
JR 0xF7 (Loop)

Which is the solution for rule paramsPlusThree. How could the system arrive at this solution
by stepwise enhancements?

One possibility is to score particular sequences of instructions which might be useful, for example
LDI A, (C)
LD B, IMM
ADD A, B
STO (C), A

This has the disadvantage of requiring some foreknowledge about the type and form of problems to
be solved.
<h1>Performance Notes
25/01/2025
Reduced cross-set breed chance to 0.001 to increase diversity on main computer.

Best Score: 56.5636
Loops: Long stretch (44 bytes) with multiple outputs, trailed by a closing loop producing
    output sequences of about 10 bytes.
Elapsed Time: 1.8105
Number of Trials: 6,048,000
Comments: More varied best set results

24/01/2025
Trial on main computer, adjusted clearance pass to 10 rounds

Best Score: 61.1617
Loops: Two overlapping loops reading the input and assigning to the output
    with a couple of bytes set with immediate values. Total executed sequence
    is 33 bytes.
Elapsed Time: 18.8172
Number of Trials: 57,184,000
Comments: There seems little gain from the modification of the clearance pass

Best Score: 55.2929
Loops: First loop to set the initial parameters, second to add incrementing
    set of numbers
Elapsed Time: 3.0535
Number of Trials: 9,792,000

24/01/2025
Generalisation of byte scores

Best Set Score: 64.924
Loops: Long double loop with a short tail loop with jump back to out-of sequence
    instruction
Elapsed Time: 22.9824
Number of Trials: 129,420,800
Comments: Locked into the same pattern for a long time

Best Set Score: 61.2908
Loops: Long double loop with a short tail loop with jump back to out-of sequence
    instruction
Elapsed Time: 5.651
Number of Trials: 32,486,400

Best Set Score: 58.8769
Loops: Two loops, the first being invoked with a CASM and RET, the second with
    a JR.
Elapsed Time: 2.6263
Number of Trials: 16,172,800

23/01/2025
Addition of convert ASCII numbers rule

Best Set Score: 57.7241 from 162
Loops: As previous, but also included a send conditional jump back which may activate
Elapsed Time: 9.2121
Number of Trials: 51,014,400

Best Set Score: 56.4711 from 162
Loops: 2 Loops, the first with a conditional branch which jumps to the second
Elapsed Time: 2.1539
Number of Trials: 12,550,400

22/01/2025
Add clearance of duplicated outputs

Best Set Score: 61.6447 from 154
Loops: 2 loops, both modified by themselves
Elapsed Time: 18.6437
Number of Trials: 85,017,600
Comments: Quite a bit faster improvement than the previous 30,000,000 trials.

Best Set Score: 59.8913
Loops: 2 Self-modifying loops
Elapsed Time: 11.5534
Number of Trials: 51,488,000
Comments: Note that it has taken 6 hours to gain 0.6 points.

Best Set Score: 59.2335 from 146
Loops: 3 self-modifying loops, bytes 0 - 47
Elapsed Time: 5.5057
Number of Trials: 21,740,800

20 - 22/01/2025
Best Set Score: 65.7074 from 146
Loops: 2
Loop Lengths: 12, 11
Elapsed Time: 2.25 Days
Number of Trials: 272,761,600
