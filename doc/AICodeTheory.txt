Theory of AI Code Selection

Contents
    Background
    Timings and Probabilities
    Example Code Combinations

<h1>Background
The goal of this theoretical framework is to develop a system capable of generating computer functions that are comparable to human-designed functions, particularly in domains such as mathematics, logic, and comparative operations.

This approach draws inspiration from two key domains:

Genetic Evolution: 
Leveraging the natural utility of probability theory in arranging codons and genes within genetic sequences.
Assembler-Type Programming: Utilizing the structure and behavior of low-level computer languages and their instructions.
The fundamental principle of genetic evolution is that probabilistic processes drive the arrangement of genetic sequences to produce useful and adaptive results. By analogy, we hypothesize that strings of assembler instructions can display similar behaviors when subjected to:

Random Manipulations: 
Introducing variability akin to mutations.
Rules with Weighted Scoring: Simulating natural selection by guiding the retention of more "fit" solutions.
This approach effectively searches for desirable examples within a vast probability space. By integrating probabilistic analysis, we aim to produce solutions that meet defined criteria within reasonable spans of time, bridging randomness with utility.

<h1>Timings and Probabilities
Generated program evaluation time for:
100 cycles of 100 breed entities per cycle and 32 trials = 320,000 trials
Completion time 37.123 seconds = 8620 trials per second.

There are 25 instructions in the instruction set and the expected useful
minimum length of code is between 6 and 14 instructions, requiring an
average of 25^9 / 2 = 1.907 x 10^12 trials to reach optimum. Hence
requiring 2.213 * 10^8 seconds per program. Clearly this is far too long
to be useful for generating optima outright.

So we have to reduce the scale of probability by reducing the number
of instructions to be selected. Let us say we can apply the monte carlo method to scoring sets of four instructions, these take an average of
23 seconds each. So we should establish the rulesets to look for such
combinations. If these combinations then combine to form others we
might find a heuristic learning generation pattern.

<h1>Example Code Combinations
LD A, (MEM)
ST (MEM), A

If we are using byte coding and we have a range of 16 valid addresses
for ST (MEM), A. Then we have a 1/25^2 chance of the instructions * 16/256 * 255/256.

