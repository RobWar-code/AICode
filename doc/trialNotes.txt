13/04/2025
Trial continues on round 673.
Seed insertions have been:
    outputSeriesOfSeries
    moduloFirstParam
    divideFirstParam

current rule is duplicateParams

11/04/2025
Reintroduced the serial processing mode, slightly faster on the
windows laptop, slower on the Linux system.

Trial now includes the greater of three rule and the sort triplets 
rule. Will add seed as required.

10/04/2025
The sortParams rule reached a score of only 11 after a day'S
processing. Added the rule sortTriplets as a step.

Added the instructions LDSI and LDSO, to allow the entities
access to sample data input and output. The aim here is to
allow the entities the possibility of evolving intelligent/
responsive code.

Started a new trial from scratch with a cleared database.

09/04/2025
Parallel Processing completed, no speed gain on the laptops,
but ready for the use of a multi-core processing unit.

The seed code for paramsOps contained an error, but this was
corrected by the system after about 100 rounds.

Pre-existing entity solutions were utilised efficiently.

The trial continues on Param Operations 7

31/03/2025
Added seed to continuing trial, operation
    multiplyAdjacentParamOp

29/03/2025
The current trial has had to have seed for:
    outputSeriesOfSeries
    moduloFirstParam
    divideByFirstParam
    greaterOfAdjacentParams
    subtractAdjacentParams
    multiplyAdjacentParams

26/03/2025

The trial using fragments completed as far as moduloFirstParam6
with a single manual insert (outputSeriesOfSeries).

Have included the rule outputScoresEqual to encourage the
use of inputs across input data trials. Current trial has
reached 24/32 at rule outputSeriesOfSeries3 with no manual
inserts by round 240.

Consider increasing the max score for outputScoresEqual
(currently 1).

24/03/2025

Added a feature of searching the seed rule programs
for fragments in common with the rule just completed.
These are then randomly incorporated into entity
breeds by monoclonalInsBreed.

Started the trial from scratch (at first rule) with
this feature added. Have used one seed program
so far (seriesOfseries), and the system is currently
working on multiply by first param 2 (round 126).

Note that is is sticking on variants that satisfy 
half of the problem set, but not both. It would
be worth pondering solutions to this form of
deadlock. (Perhaps extra points for scoring equally
in each trial execution cycle(input block)).

19/03/2025

paramOperations - divide reached 12/16 after about
18 hours.

Restarted the trials from scratch using the seed
rules.

18/03/2025
Readded output difference checking, with refinement
of calculating the optimum from predetermined outputs.

In the scoring for rules am now taking account of consecutive
correct values from the start of the output to encourage
serial processing.

Trial on paramOperations - modulo now running.
Seed for the modulo inserted. So trial proceeded
to paramOperations - divide.

15/03/2025
The subtract paramOperations completed, but the
system got stuck on the multiply paramOperations
rule, so am hand crafting that. Will also introduce
a divide paramOperations rule and a modulo paramOperations
rule.

The system reached a score of 11.4/15 on the modulo
paramOperations rule. It is worth noting that the
solution it evolved was a primarily blind pattern
of numbers applied to both instances of the input
data. So it is worth re-introducing the outputDifferent
rule, to ensure that experimentation with the inputs
takes place.

14/03/2025
The system got stuck on the add paramOperations
so have created the seed code for this. New trial
running.

The system is now working on the subtract paramOperations.
This scored 10.9/15 after 140 rounds, so introduced the
seed program and continued trial.

13/03/2025
The trial of paramOperations rule got stuck at
24/45 after 1 day's processing. So splitting
the problem into smaller rules.

Still stuck on simplfied rules, so provide further
simplicity by add in the rules as individual examples.

The = operation completed naturally

12/03/2025
Trials have worked through all the rules upto
paramOperations which is currently running at 45%
of the score. This rule probably needs breaking
down into stages.

Have supplied 4 hand-crafted solutions out of a total
of 36 rules.


08/03/2025

System stuck on divideByFirstParam - so will write
the seed for that and allow the system to proceed.

The new envisioned goal is to provide code that the
system gets stuck on and build-up a library of auto
and human generated solutions that can be merged,
mutated and permuted by the system to provide new 
solutions.

It is worth noting that the divideByFirstParam
rule reached a score of 15/20 achieving division
by 2 on the first half od the problem in 577 rounds,
proving that it was still capable of improving over
time, but not within acceptable time frames on these
resources. So we can see that we are engaged in either
reducing the size of the probability field, or of
speeding processing.

07/03/2025
Removed the instructionCount rule from circulation.
Results achieved much sooner in terms of rounds, 
including seriesOfSeries3. Got stuck on modulo [5,6]
rule.

The new policy is to provide a seed program for every
rule that gets stuck at 140 to 160 rounds. These
seed programs can then contribute to the search for
solutions in other cases.

For the next trial modified the instructionCount rule
and re-included it. Provided a seed for modulo rules.

06/03/2025
Introduced more fragments and ran a trial of seriesOfSeries3
on its own, to overcome the problem of seed contribuants
causing early entrapment. Score is currently 38/52 with
scattered output after 111 rounds. Leave this to reach 180
rounds.

Suggestion is to modify the other series so that they do
not have a single value for a parameter, this should help
to prevent "ghost" values and repetitions of code appearing.
We could also have a rule to exclude CALL which was used
to create a list of repeated block calls, in preference to
controlled loops.

The trial excluding CALL statements reached 36.5/52 after
212 rounds on seriesofSeries1, achieving 2 series out of 5.

Have now included a futher fragment that represents loops
more thoroughly. This is currently under trial. This made
no significant difference.

As a further approach we can write a script as seed and 
insert when the relevant rule is reached. We can justify
this in terms of the projects processing goals only, in
the building-up of example seed code to be used via
permutation and combination in other situations.

This approach has cleared the rules as far as part of
the modulo rules. Will supply the modulo solution and
insert it, as for seriesOfSeries.



05/03/2025
The system got stuck on the rule seriesOfSeries3 at 33/44 
after 420 rounds. The code consists of a stochastic unconditional
loop which makes a single reference to the input parameters

This suggests that it would be useful to reward the number of
parameter reads in the first block of code. So we include the
rule numInputReads in the ruleset for the next trial.

This trial reached 42/52 after 200 rounds. So have reduced the
range for the numInputReads to the first 16 instructions, rather
than 42.

Next consider the number of JRNZ instructions in the first
section of code.

04/03/2025
The score on seriesOfSeries3 after 540 rounds is 34
out of 44, on the windows PC.

The score on seriesOfSeries1 after 160 rounds is 31
out of 44 after 160 rounds, on the linux PC.

Will leave for a few more hours to see if there is
any improvement, whilst I attempt a rethink of the
templates and fragments approach.

One possibility is to reward the presence of certain
instructions in the primary execution group (0 to 30).
Discussion in WorkedExamples.

Decision is to try more small code fragments such as
    LDI A, (C)
    INC C
    ST (MEM), A

Using upto 5 instructions.

Having added this feature, the system reached 32/44
in 180 rounds, so this was not an improvement.

Next-up increase the highIP for this rule to 42 to
allow more scope for variation.


03/03/2025
The trial on the windows laptop reached 37 from 44
after 400 rounds on seriesOfSeries3.

Have now set the number of best sets back to 64
as allows more depth of searching in a given time.

02/03/2025
Ran trial with seriesOfSeries1 parameters:
[2,16,5], [5,16,5], [7,16,5], [10,16,5]

This achieved the target distributions of outputs, but
not the instruction count score, because it had evolved
the output result, rather than efficiencies of code.
We can try weighing more in favour of efficiencies of
code instructionCount. We can also include the highestIP
rule to favour compact code.

Having included the highestIP at 28. The system scored
31.1 out of 44 after 165 rounds.

What would be good to determine is whether this is a 
logical/probabilistic trap or whether it is a statistical
anomaly.

On the next trial the number of best sets is increased
from 48 to 64, the clearance pass from 15 to 20 and
the number of process main loops decreased from 10
to 5.

Using this combination, the system reached 37 out of 44
in 72 rounds. The first seriesOfSeries rule was completed
on round 95, after 75 rounds.

The system got suck on seriesOfSeries3, scoring 37 out of
44 after about 400 rounds. It was stuck on the second parameter
as 4.

Have modified the first parameter to break-up patterns
established by the prior run.
    3: [3,3,5], [6,5,4], [9,4,4], [11,4,5]

The basic problem is to get it to use a loop based on
the second parameter. It may be better to use more
widely spaced values for the second parameter,
try:
    3: [3,12,5], [6,4,4], [9,7,4], [11,3,5]



01/03/2025

Even with the insertion of another seriesOfSeries rule
the second did not complete in 160 rounds.

The problems have the parameters
1: [2,4,5], [5,4,4], [7,4,4], [10,4,5]
2: [2,3,5], [5,5,4], [7,4,4], [10,4,5]

The first parameter refers to the series interval,
the second, the length of the series and the third
the number of times the series is repeated.

The first example (where the length of the series is the same) 
is solved within 10 rounds.

So the problem is getting the system to use the second parameter
to control a loop rather than guessing.

The main of the difficulty for adjusting is that the code uses
repeat sections of code rather than loops. So if for example,
we make the first seriesOfSeries 8 long rather than four, 
we have a higher chance of a loop being selected.

28/02/2025

Added the rules outputSeries and outputSeriesOfSeries, which
take their cue from the input parameters.

Initial trial completed outputSeries in 4 rounds, but was
still stuck on outputSeriesOfSeries after 140 rounds.

Loosely, the things to consider are the transference of
code learned for other problems and the complexity of
a transform/innovation.

Add another outputSeriesOfSeries rule with the repeat
parameter set the same.

The new outputSeriesOfSeries rule allows the system to
reach score 21 in 40 rounds - faster than being without.
But it remains to be seen whether it will complete
the task in satisfactory time. Little progress at
70 rounds.

27/02/2025

Introduced code templates and fragments to the instruction
set module. Part of the argument for this is that such combinations
of code might arise by chance.

Ran a trial with the templates and fragments, no noticeable
difference to outcomes.

The system has been stuck for a very protracted time on
module (5,6) and this trial is now abandonned.

The problem is to create rules in which the adaptive steps
from on to another are sufficiently probabilistically
small.

Am adding the rules outputSeries and outputSeriesOfSeries 
to aid the development of loops as seed for other problems.

26/02/2025

Re-introducing the instruction count rule worked for
the same set of rules as worked previously. But the
system still gets stuck on the combined modulo (5,6).

So the challenge here is to come-up with a more effective
way to combine prior solutions. This is discussed in the
WorkedExamples document.

25/02/2025
The system got stuck on modulo (5,10), so have started
a new trial with the essential numbers (2,3,4,5,6,7) as
individual rules. If these work they will lead on to
a combined trial.

These things bring to mind one of the fundamental issues
of what we are trying to accomplish - which is whether
to tackle a problem as a direct mapping relationship
or whether to apply an algorithmic function.

Note also that algorithmic functions may also be sets
of conditional mapping relationships.

After a trial of 60 rounds, the modulo combination (5,6)
reached a score 9.4/12

Have re-introduced the Instruction Counter score to
favour shorter (ie: algorithmic type) solutions.

24/02/2025

This time the system got stuck on divideBy (3,4).
this is basically because of the difference between
the divide methods for 3 and 4 using the SR A 
instruction. If we remove the SR A and SL A instructions,
likely it will use SUB A, B for the general method.

23/02/2025

divideByFirstParam 3 got stuck for about 400 rounds with
the first params being (3, 6).

Have now introduced a prior rule with params (4, 6) -
ie: both even, one being a power of 2.

This rule reached 11.3 after 238 rounds - still too
long to be practical and subject to random number
inserts rather than algorithmic products.

If we use say 4 input parameter blocks rather than
2 we reduce the chance of the system using ghost
values rather than reading the first parameter,
furthermore, we are more likely to get a general
result for the operation rather than a program
specialised for a particular number.

A likely problem with this approach is that it
would be trying to solve too much in a single
pass.

Since the appearance of a ghost parameter provides
a partial solution, it is still worth generating.
So perhaps the two approaches can be combined,
using two parameter blocks of the first few rules
and then more on the subsequent. This would allow
the individual, partial solutions, to be merged
into a single general solution.

22/02/2025

Having introduced the additional multiplyByFirstParam rule,
the trial completed the multiply rules by round 64. It
then got stuck for over 250 rounds on the divide rule, so
have now introduced additional divideByFirstParam rules
(2,4; 3,6).

Restore selected rule seed works correctly.

Divide by first param (2,4) was completed in 3 rounds.

The second divide by rule was at score 7.5 after 80 rounds.
Introducing another rule (2, 3).


20/02/2025

The trial got stuck on second multiplyByFirstParam rule
(3 and 9) for more than 300 rounds. Have introduced an 
oddAndEvenParams rule, to see if this helps. Also introduced
an additional multiply rule (6 and 5).

19/02/2025

The trial on the windows computer got stuck at score 9.75
for rule paramsCompareN (12) after 229 rounds, so this
run was abandonned. All preceding rules were completed
by round 160.

On the current set-up, it looks as though runs of several
days would be necessary.

Have removed the rules with "ghost" parameters and replaced
them with rules that use the first input parameter.

Extended the clearance pass cycle to 15 to allow novel
solutions to catch-up with current ones.

This trial is commenced at midday today.

It took until round 20 to complete the rule addFirstParam.

However it took only 2 rounds to complete the subsequent 
subtractFirstParam

Halted the trial at round 124 having not completed the 
multiplyByFirstParam rule. So inserted another rule
for multiplication (2 and 4, 3 and 9) to divide up the task.

New trial started.


18/02/2025

The paramsGreaterThanN rule took 11 rounds to complete
The paramsCompareN rule took 131 rounds to complete
However, the paramsTimesN (6) rule had only got to
score 6.8 after 100 rounds, so some new factor has come 
into play here.

This last problem may be due to the overuse of the
seed-rule. The frequency of this has been adjusted 
downward for the next trial.

The trial got stuck on paramsTimes(N) 22 for over
100 rounds. This is a substantial downgrade from
earlier trials and may be due to the order of rules,
the lowering of the seed rule trials or the addition
of the SL A and SR A instructions.

Try increasing the seed rule frequency and moving the
comparison rules after the times rules.

The paramsTimesN (2) rule completed in two rounds
using the SL A instruction.

However, this has made it more difficult for the
paramsTimesN (6) rule to learn from the previous
rule, and this has taken 36 Rounds to reach score
6.5

Whether to introduce a paramsTimesN (3) rule as
an intermediary step?

Whether to supply certain parameters via special
instructions - or better to rely on the existing
parameter block?

Use add/minus/subtract/times/divide first param rather
than "ghosting" the parameter.

There was no speed advantage to adding a ghost value
preceeding the add first param rule.

17/02/2025

Having set the rule pass score to 9.9/10 we find that
the paramsGreaterThanN rule takes more than 220 rounds.
The previous trial did not include the output case in which
a === b, since the score was 9.5/10.

However, since the output result requires 8 zeroes on trial A
and 5 on trial B, this clashes with the valuesOutSet rule, so
that the maximum score attainable on the correct result is
9.8437

We can fix this by having 1 = <, 2 = =, 3 = > and thereby
avoiding zeroes on the output. 

The output code required is something like:

ie:
LD A, IMM 2
LD B, IMM 112 (or greater)
// Output 2's
STO (C), A
INC C
DEC B
JRNZ 0xFD
LD C, IMM 0
LD B, IMM 12
// Loop
PUSH A
LD A, IMM 16
LDI A, (C)
CMP A, B
JRC       // 12 > A
JRZ 4     // A === 12
LD A, IMM 3 // A > 12
STO (C), A
JR 8   // Next
// A === 12
LD A, IMM 2 // A === 12
STO (C), A
JR  3 // Next
// A < 12
LD A, IMM 1
STO (C), A
// Next
INC C
POP A
DEC A
JR NZ E9 // Loop
RETF

Points Arising

As a general rule the required output data should not have
more than 2 or 3 zeroes.

Where the number of output values is small, the random output
of numbers should not mask the logic required so the minimum
number of same outputs in such samples should be about four or
five and these should be scattered through the data so that they
are best elucidated by logic.

In the case of the paramsGreaterThanN function, it is suggested
that the parameter inputs should be set to reflect these things.

For the next trial, I have supplied the parameters to the 
paramsGreaterThanN function directly, this time with five
or six inputs scattered, which should provide the range outputs.
I have also added the SL A and SR A instructions.

Further Trials

The trail with the original data was still stuck at score 9
after 137 rounds.

The trial with the data reached score 9.4367 by 61 rounds.
So we have proven the general principle that sample input data
is significant.

The next attempt is to split the rule into two - first
with paramsGreaterThanN then paramsCompareN

This trial took 11 rounds to complete the rule paramsGreaterThanN

As general rule it is better from a practical point view not
to allow testing to go beyond 45 - 60 rounds for an individual rule.
If a rule reaches this without passing, it would be better to
rework it in some way.


16/02/2025

Latest trial with LD A, R, LD A, S removed in response
to unpredictable results with paramsGreaterThanN.
Trial without these is stuck on the rule after 71
rounds. So moving the rule back to the position after
paramsMinusN, as subtract is more likely to be useful
as a step.

Have decided to leave the idea of the faster computer
until finances are more settled. Better to focus on
rules that can proceed in reasonable time and to consider
ways in which the output from these can be combined/re-utilised.

The paramsGreaterThanN rule was completed after 87 rounds
when following paramsPlusN (6).

By positioning the paramsGreaterThanN rule after paramsMinusN,
the rule was completed by round 27.

Restarted a trial with all the current features - intention
is to leave it to run for up to three days, before doing
further development work with new rules.

Need end of job functionality. (Completion of all rules)

11/02/2025

It is now clear from the proceedings that time scales
required to pass each rule are too large using this
existing technology (laptops). Options are: 

1) To obtain a quad computer and parallelise the main
processing loop.

2) To rewrite the backend in PHP and use my existing server, using
parallel threads.

The first solution requires time to obtain the finance.

09/02/2025

The new rules and instructions were added. The resultant
times were as follows:

Rule      | Rule                                 | Round
Sequence  |                                      |
0         | outputMatchesInitialParams           | 1
1         | paramsPlusN (3)                      | 5
2         | paramsPlusN (6)                      | 6
3         | paramsMinusN (3)                     | 8
4         | paramsMinusN (6)                     | 12
5         | paramsTimesN (2)                     | 13
6         | paramsTimesN (6)                     | 14
7         | addFirstParam                        | 20
8         | addSecondParam                       | 28
9         | duplicateParams                      | 127
10        | skipAdjacentParams1                  | 175
11        | skipAdjacentParams2                  | >190

Note the large gap between addSecondParam and duplicate params
and that this has been performed much more quickly previously.
We cannot be certain that this is not just a statistical quirk.
But we can investigate the code. See WorkedExamples.txt.

Fixed error in paramsTimesN, adjusted scoring by removing exponent
since we are doing one rule at a time. New trial started.

Suggest changing the number of rounds in a clearance pass to
10 as standard, rather than letting it grow longer and longer
as more rounds pass, since we are dealing with longer trials.




08/02/2025

Changed the length of the output field data to 16 bytes
rather than 8. Replaced paramsPlus/MinusThree by 
paramsPlus/MinusSix to obviate the appearance of
INC A, INC A, INC A rather than ADD A,B. However we
note that in today's trial the system used the crafty
trick of substracting 250.

The addAdjacentParams rule remains problematic so some
form of intermediate rule is required.

Having observed that paramsTimesTwo now takes at least
70 rounds, it seems necessary to reintroduce paramsPlusThree
and paramsMinusThree

So the following rules are to be introduced / adapted:
    paramsPlusN - where N is supplied in the rule
    paramsMinusN - where N is supplied in the rule
    paramsTimesN - where N is supplied in the rule

In addition, the instruction set will be modified to
include the instructions JRNZ and JRNC

Note that in fact paramsTimesTwo lacked the qualifier & 255,
so these results were invalid.

07/02/2025

Having added the rule greaterThanAdjacentParam we find
that although this rule is completed (after 72 rounds),
the code produced matches by rescrambling the inputs,
not by using the CMP or SUB operations. This demonstrates
a basic weakness in the design. It could be overcome
by using 16 bytes of output data rather than 8, making
coincidences of arrangement between the two input datasets
less likely. This kind of effect could be defined as
"Right answer, wrong method".

06/02/2025

Having added rules add first param and duplicate params
 
Overnight Run

Rule      | Rule                                 | Round
Sequence  |                                      |
0         | outputMatchesInitialParams           | 1
1         | paramsPlusThree                      | 10
2         | paramsMinusThree                     | 12
3         | paramsTimesTwo                       | 14
4         | addFirstParam                        | 15
5         | duplicateParams                      | 19
6         | skipAdjacentParams1                  | 63
7         | skipAdjacentParams2                  | 94
8         | swapAdjacentParams                   | 97
9         | addAdjacentParams - not completed    | >271

Added the rule addSecondParam to see if this would accelerate
the completion of rule 9.

05/02/2025

Introduced duplicate and transpose mutations to monoclonal
breeds.

The following were obtained on an overnight run:

Rule      | Rule                                 | Round
Sequence  |                                      |
0         | outputMatchesInitialParams           | 1
1         | paramsPlusThree                      | 5
2         | paramsMinusThree                     | 18
3         | paramsTimesTwo                       | 20
4         | skipAdjacentParams1                  | 27
5         | skipAdjacentParams2                  | 104
6         | swapAdjacentParams                   | 107
7         | addAdjacentParams - not completed    | >149

Suggested changes:
Add the following Rules:
    duplicateParams
    paramsPlusFirstParam

Include an interbreedInsMerge breed method to favour combinations
of proven code.                 

04/02/2025
The main system had not completed rule sequence num 4 (skip
adjacent params) by 160 rounds.

The windows system had not completed rule 6 by 340 rounds -
this rule has yet to be completed.

03/02/2025

Got to rule 6 (addAjacentParams) after 125 rounds, completing
the skipAdjacentParams and swapAdjacentParams rules. The question
is whether the completion of these two rules adds to the speed
of completing rule 6.

Note that the completion time of rules is quite variable from run to
run.

On the trial run, the system reached rule 4 (skipAdjacentParams) in just
26 rounds, showing just how wide the variance in time taken is.
 
02/02/2025

Added the rules addAdjacentParams and subtractAdjacentParams
to try to ease the passage to multiplyParamsByEachOther.

Currently the rate of progress is about one rule every 20
rounds. Although after a couple of trials, we find that there
is substantial variation in the amount of time taken to reach rule
4 (addAdjacentParams).

At rule 4, the system gets stuck, so this still requires an
intermediate step. Consider swapping around the adjacent 
parameters, which involves fewer instructions.

01/02/2025

When the output address was set to start at 0 for each rule
results were much more rapid, although rule 3 (multiply params
by 2) had not been solved after 100 rounds.

Changed the input block for multiply params by 2, to 0. rule solved
by round 5, using lower threshold.

Now the system sticks at rule sequence 4 (multiply parameters
by each other) - since this is a complex loop, it would be better
to include an intermediate rule such as add parameters to
each other, or subtract parameters from each other or both.

31/01/2025

Established the selection of only one rule at a time using
the result of one completion as the seed for the next.

Trial on windows computer switched to the second rule after
14 rounds. The second rule had still not been solved after
150 rounds.

Since the rules are operated one by one, it may well be 
better to use the same output addresses for each rule, as
this would potentially save a few instruction modifications
on the entities.


29/01/2025
After 180 rounds, the main computer scored about 28 points
out of a possible 34, with a few hits on the second rule.
This was achieved with a loop of 61 bytes, which put outputs
into two sections, the first extending into the first rule
area and the second starting at the second rule area.

Set the score exponent to 1.01 on the main computer. Trial
reached the second rule in < 21 rounds.

Terminated the trial on the windows system as more or less
frozen performance after 180 rounds. Many scores the same.
Next change suggested - eliminate incidences of duplicate
scores, even if they are not the best.

In no case has the progress on the second rule been significant.
In order to try to overcome this, we can reduce the threshold
for the second rule to 0.8, rather than 0.9, to allow for more
diverse solutions.

With the threshold set to 0.8 the second rule began at 7 rounds.
Allowing for the threshold of resistance to change being set
to 1.01, we may see an improvement in progress on rule 2. But
whether this is at the expense of the quality of solutions in
rule 1 we shall see. After 57 rounds the highest score was
still only 26, so there must be some probabilistic obstacle
to further progress. After 85 rounds, the situation was the same.

Restart the trial with both rules from the start, to see how much 
difference that makes in about 40 or 50 rounds. At 34 rounds the
scores reached 24 points, so dealing with two rules is at least
exponentially slower than dealing with one, this makes sense when
we consider the additional combinations of instructions required.

If we save the successful result of the first trial and then restart
to do the second, then this should in theory take the same amount of
time as the first. Would such saved solutions be useful and how could
they be made further use of, assuming we were aiming at an escalator
of capabilities?

Let us adapt the program so that when it completes a problem, it saves
the solution, then leaves that problem to begin another, using the
foregoing as the seed. Would this be better than starting from scratch
or worse? It is worth a trial. Because the seed will effectively score
zero on the new problem, how do we introduce it?

We can use the seed program rather than random code in the breeding
stage of each entity program, but still retain the other breeding
methods (monoclonalByte etc.).  


28/01/2025

Set-up trial excluding the code combination rules.

This took 71 or 72 rounds to reach the 90% mark for the 
scoring on the first rule (valuesOutMatchInitialParams)

In parallel to this is a trial to make the system slightly
less conservative, setting the score exponent to 1.5
instead of 2. This took 32 rounds to achieve the first result.

Restarted the trial with an exponent of 1.2 on the main computer
and 1.5 on the faster, windows computer.

With the exponent set to 1.2, the system transitioned to the
second rule (paramsPlusThree) in less than 27 rounds. However
it had made little progress on the second rule after 60 rounds.

After less then 117 rounds, the windows computer began the
second rule.


27/01/2025
The preceding day's results prove that as rules are added,
earlier rule results decay as the new conformancies rise,
so that there is an averaging-out process.

I have re-added exponential scoring, so that the "cost"
of disinvesting in a solution is higher than a gain in
another solution. Early testing seems to indicate that
general improvements proceed. Yet to see transition to
a second rule.

Next is to use best score thresholds to mark the introduction
of each new rule to the entities. But it is possible that the
addition of the disinvestment cost is sufficient to permit
timed introductions to work effectively.

Having added in rules for code combinations, the results
were extremely poor. 60,000,000 trials and only a score
of 37 out of 42 for the first challenge 
(valuesOutMatchInitialParams).

The system performed better without these rules.

26/01/2025
Reduced the cross-set breeding to 0.001 to increase variety,
but this still moves toward the general solution of a list
of series preceded by a match of input params, at which point
the system sticks.

The basic problem is that the development of programming solutions 
is not strictly an incremental, step-wise system. Reason uses manoeuvres
to get to arrangements of code, not chance insertions, replacements
and deletions of code. So there is a layer of logic missing
in the approach. Bearing this in mind, we will pause to reflect
and to ponder how the missing layer might be defined and filled.

Another way of saying this is that gradations are fundamental to
evolution. Assemblages (such as code or DNA) are necessary for
the preservation and conveyance of state in the system.

Revisited the idea of using single rules at a time. This time
allowing a single rule, to sample how long it might take to achieve
a reasonable result. Used the rule valuesOutMatchInitialParams,
with the background rules initialParamsPreserved, valuesOutSet
and valuesOutDifferent. This took 26 rounds to achieve 7.5 out 8.

Then added in the rule paramsPlusThree to begin at round 27.
At round 53, the best result was almost a complete set of the
original problem plus three of the newly added rule. 

The results work out best if the previous score is close to its
threshold, so the next adaptation is to introduce each new rule
as the threshold is approached (max - 1?) and to perform them
in the required order.


25/01/2025
Ran two attempts in parallel, with clearance pass 5 on one and
10 on the other. Similar results.

Now trying reduced cross-set breeding (0.001) to attempt to
diversify trial attempts.

Next objective - study the probabilities of progressive code
variations that might lead to improved results.

24/01/2025
Have adjusted the byte scoring to score zero for a hit and 255 for
a miss. Had an interesting result where I had changed the scoring
to give an idea of proximity to the correct result. The system used
this as a cheat to obtain the correct result!

Currently, I observe that what we are trying to achieve is to pluck 
the required results from a probability field, where we are uncertain
of the scale of the probabilities involved and therefore do not know
how much processing time is required.

From this standpoint it makes sense to put more effort into examining
probabilities, rather than measuring it empirically, which is what the
trials involve.

From the cheat result, we note that the system rapidly evolved a method
involving about 8 instructions, for solving scores in each problem
space. So we know empirically that we can achieve optimal solutions
that involve 8 instructions.

The trials thus far have proved that the system tends to evolve one
rational solution loop (transfer of input to output) and then a statistical
loop which scatters random numbers to the other problem spaces, some
of which incidentally score in those spaces. It does not yet evolve 
algorithms that are effective on the problem spaces.

21/01/2025
After about 30 million trials, the system tends to evolve two loops
which spread series through the output, with random score hits in
the output areas. There is no sign of algorithms to match specific
requirements from the inputs to the outputs.

The two loops tend to be of about 12 or 13 bytes in length (10 or 11
instructions). Also included is a termination condition in which 
multiple PUSH operations eventually break the end of the loop so
the program terminates in a string of NOOP operations.

As far as the system "works" it can be said to demonstrate increasing
sophistication. As far as finding specific solutions in finite time
we observe that it is not a practical solution.

So the next stage suggested is to increase the number of problems
set in the input space (since we have about 128 bytes remaining)
and allow the system to "explore" this space, coming-up with whatever
approaches it may evolve over a period of 10 to 20 days, if this
proves practical or desirable.

The things to watch-out for include getting trapped in particular 
solutions or whether the system continues to maintain sufficient
diversity to make steady score progress (albeit slow).

20/01/2025
The system quite rapidly resolves to a single solution - suggested
measures:

Increase the number of best sets to 48.

Decrease the frequency of cross-set breeding.

Increase the period between pass clearances.

Reaches 61 out of 146(max) over 60 million trials.


19/01/2025
Added score for reverse jump loops to encourage multiple score space
solutions.

Added routine to remove duplicate scores in the clearance pass.

After four hours have results of 57 versus 146 (max) just over
1/3. Will leave trial for about 18 or 20 hours.

Consider checking whether the loop back code is actually used as
well.

18/01/2025
Tried exponential scoring to see if it would produce specialisations,
instead no hits were scored at all against rules other than series,
different and params match.

Consider scores overlaying a single section of output.

16/01/2025
Introduced breeding from sections of code marked as used.

Flattened the scoring

Checked out simple seeding

Trial still produces scores of between a third and a half
after 20 million trials.

It is possible that seeding combined with the flagged
blocks interbreeding will improve matters. This is to
be the next trial. Accelerates development for a little
while, but soon hits the same plateau.

Reduce the the scores for the output only rules.

13/01/2025
Introduced staged rules

Introduced byte level mutations for monoclonal breeding as well as
instruction level.

Run to test byte level mutation underway. Staged rules made no appreciable
improvement over earlier attempts in a 10 hour, 16 million trial run.

The difficulty in the development of the entities remains the issue of
restricted probability pathways and the sheer fact of very low probabilities
of useful code arising.

Next stage, further the development of seed code/templates.

09/01/2025

Rulesets rearranged and added params -3. Increased number
of best sets to 32. 

Score still tends to settle at 1/3 or just below, scatterings
of random numbers and series.

Suggestions for work:

Localised interset breeding.

Paginated long range memory.
    256 byte pages referenced by 
        LDF A, (DC)
        LDF A, (MEM)
        STF (DC), A 
        STF (MEM), A 
        CFAR
        CFSM
        Additional reg D for 16 bit addresses

05/01/2025
All of the changes suggested were made, but the app still
plateaus at a score of about 1/3 of the maximum, presumably
because optima found at this level, do not provide a reasonably
high probability of finding an improvement. So we move back
to analysis to see what improvements might be made.

see WorkedExamples.txt

25/12/2024
Introduced a set of new instructions for the B and C registers.
Changed the number of best sets to 24 with just 40 entities in
each to overcome traps a bit better.
Increased the maximum instruction execution count to 2000 from 1000
to see whether the increased diversity would help.

Introduce a TSTO instruction which returns a 0-255 score in the A reg
for the last output value.

Consider introducing a rule for the adding together of adjacent
parameter inputs.

Consider including key words/symbols in the input data with examples,
ie: + a b, - a b, * a b, / a b
 
Meanwhile consider better strategies for code grouping.

13/12/2024
Tried increasing the number of best sets from 4 to 8. No particular
gain, progress slower, set back to 4.

Fixed problem with the instruction set (missing break; statements).

Ran an overnight run of about 48,000,000 trials. Little progress.
Try including memory transfers using register relative addressing.
This increases the size of the instruction set, so need to rework
the calculations accordingly.

Included the instructions ST A, (C) etc, for indexed addressing.
Initial gains large, but there appears to be a problem with breeding
methods, as gains are extremely slow after about 5 or 10 minutes.

11/12/2024
Multiple best sets included. Separated input output memory into
separate blocks of 256 bytes and included the relevant instructions
in the instruction set.

Achieved a 100% trial in 9 hours (20,000,000 trials), but it is rarely 
repeatable.

A great deal seems to depend on the initial selections, so will extend
the period of random generation per best set to several cycles.

07/12/2024
Having included the placing the outputs and parameters in
separate memory chunks and allowing for fixed block interbreeding
the scores to about 50% of the max in 45 minutes.

The next trial is to have separate best sets that interbreed with
each other periodically.

06/12/2024
The alternate input parameters approach improves matters only
slightly, the primary issue is that local optima are identified
by the system by simply placing (random) numbers in the output
rather than by the use of probabilities. This is because the
output sample sizes are small (4) so the chances of the random
numbers being on target can be higher than that of sequencers.

To overcome this, we can separate the parameter and output blocks
into separate chunks of 256 bytes and use different instructions
to access each.

04/12/2024
Having run the procedure for 5 hours (about 45,000,000 trials) a 
mediocre result was attained mostly consisting of random insertion
of numbers in the output fields.

Since the aim is to provide general operative functions, we need a
procedure to encourage this.

So let's try alternating the input parameters and using the same
rule set. The scoring can be done for each parameters set.

31/11/2024

Having managed to get as far as sequences of numbers in the top scoring position,
I decided to see if I could get more variant results by dividing up the ruleset
examinations of the output values into sections. The initial results are not
particularly promising although I may be able to compensate with counter-prevailing
rulesets (particularly a negative score for values of output left the same).

An option to consider is multiple best sets to overcome the problem of the
system getting trapped in probability dips arising from initial choices.

We may be able to distinguish in our trials between current selection scenarios
and those arising from ruleset weightings. The issue is to try to limit the
range of possible trial parameters.

At the present time the system is sticking with values still set to zero
in the output areas, let us try the rule that something is better than
nothing. If this rule is weighted at 100, it emerges as the prevalent
and produces a series on the output. What is more, variety is maintained
amongst the best set.

So if we now try upping the rating for multiply by two slightly, we maintain
the instability.

So we juggle the weights accordingly.
