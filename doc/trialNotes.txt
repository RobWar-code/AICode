02/02/2025

Added the rules addAdjacentParams and subtractAdjacentParams
to try to ease the passage to multiplyParamsByEachOther.

Currently the rate of progress is about one rule every 20
rounds. Although after a couple of trials, we find that there
is substantial variation in the amount of time taken to reach rule
4 (addAdjacentParams).

At rule 4, the system gets stuck, so this still requires an
intermediate step. Consider swapping around the adjacent 
parameters, which involves fewer instructions.

01/02/2025

When the output address was set to start at 0 for each rule
results were much more rapid, although rule 3 (multiply params
by 2) had not been solved after 100 rounds.

Changed the input block for multiply params by 2, to 0. rule solved
by round 5, using lower threshold.

Now the system sticks at rule sequence 4 (multiply parameters
by each other) - since this is a complex loop, it would be better
to include an intermediate rule such as add parameters to
each other, or subtract parameters from each other or both.

31/01/2025

Established the selection of only one rule at a time using
the result of one completion as the seed for the next.

Trial on windows computer switched to the second rule after
14 rounds. The second rule had still not been solved after
150 rounds.

Since the rules are operated one by one, it may well be 
better to use the same output addresses for each rule, as
this would potentially save a few instruction modifications
on the entities.


29/01/2025
After 180 rounds, the main computer scored about 28 points
out of a possible 34, with a few hits on the second rule.
This was achieved with a loop of 61 bytes, which put outputs
into two sections, the first extending into the first rule
area and the second starting at the second rule area.

Set the score exponent to 1.01 on the main computer. Trial
reached the second rule in < 21 rounds.

Terminated the trial on the windows system as more or less
frozen performance after 180 rounds. Many scores the same.
Next change suggested - eliminate incidences of duplicate
scores, even if they are not the best.

In no case has the progress on the second rule been significant.
In order to try to overcome this, we can reduce the threshold
for the second rule to 0.8, rather than 0.9, to allow for more
diverse solutions.

With the threshold set to 0.8 the second rule began at 7 rounds.
Allowing for the threshold of resistance to change being set
to 1.01, we may see an improvement in progress on rule 2. But
whether this is at the expense of the quality of solutions in
rule 1 we shall see. After 57 rounds the highest score was
still only 26, so there must be some probabilistic obstacle
to further progress. After 85 rounds, the situation was the same.

Restart the trial with both rules from the start, to see how much 
difference that makes in about 40 or 50 rounds. At 34 rounds the
scores reached 24 points, so dealing with two rules is at least
exponentially slower than dealing with one, this makes sense when
we consider the additional combinations of instructions required.

If we save the successful result of the first trial and then restart
to do the second, then this should in theory take the same amount of
time as the first. Would such saved solutions be useful and how could
they be made further use of, assuming we were aiming at an escalator
of capabilities?

Let us adapt the program so that when it completes a problem, it saves
the solution, then leaves that problem to begin another, using the
foregoing as the seed. Would this be better than starting from scratch
or worse? It is worth a trial. Because the seed will effectively score
zero on the new problem, how do we introduce it?

We can use the seed program rather than random code in the breeding
stage of each entity program, but still retain the other breeding
methods (monoclonalByte etc.).  


28/01/2025

Set-up trial excluding the code combination rules.

This took 71 or 72 rounds to reach the 90% mark for the 
scoring on the first rule (valuesOutMatchInitialParams)

In parallel to this is a trial to make the system slightly
less conservative, setting the score exponent to 1.5
instead of 2. This took 32 rounds to achieve the first result.

Restarted the trial with an exponent of 1.2 on the main computer
and 1.5 on the faster, windows computer.

With the exponent set to 1.2, the system transitioned to the
second rule (paramsPlusThree) in less than 27 rounds. However
it had made little progress on the second rule after 60 rounds.

After less then 117 rounds, the windows computer began the
second rule.


27/01/2025
The preceding day's results prove that as rules are added,
earlier rule results decay as the new conformancies rise,
so that there is an averaging-out process.

I have re-added exponential scoring, so that the "cost"
of disinvesting in a solution is higher than a gain in
another solution. Early testing seems to indicate that
general improvements proceed. Yet to see transition to
a second rule.

Next is to use best score thresholds to mark the introduction
of each new rule to the entities. But it is possible that the
addition of the disinvestment cost is sufficient to permit
timed introductions to work effectively.

Having added in rules for code combinations, the results
were extremely poor. 60,000,000 trials and only a score
of 37 out of 42 for the first challenge 
(valuesOutMatchInitialParams).

The system performed better without these rules.

26/01/2025
Reduced the cross-set breeding to 0.001 to increase variety,
but this still moves toward the general solution of a list
of series preceded by a match of input params, at which point
the system sticks.

The basic problem is that the development of programming solutions 
is not strictly an incremental, step-wise system. Reason uses manoeuvres
to get to arrangements of code, not chance insertions, replacements
and deletions of code. So there is a layer of logic missing
in the approach. Bearing this in mind, we will pause to reflect
and to ponder how the missing layer might be defined and filled.

Another way of saying this is that gradations are fundamental to
evolution. Assemblages (such as code or DNA) are necessary for
the preservation and conveyance of state in the system.

Revisited the idea of using single rules at a time. This time
allowing a single rule, to sample how long it might take to achieve
a reasonable result. Used the rule valuesOutMatchInitialParams,
with the background rules initialParamsPreserved, valuesOutSet
and valuesOutDifferent. This took 26 rounds to achieve 7.5 out 8.

Then added in the rule paramsPlusThree to begin at round 27.
At round 53, the best result was almost a complete set of the
original problem plus three of the newly added rule. 

The results work out best if the previous score is close to its
threshold, so the next adaptation is to introduce each new rule
as the threshold is approached (max - 1?) and to perform them
in the required order.


25/01/2025
Ran two attempts in parallel, with clearance pass 5 on one and
10 on the other. Similar results.

Now trying reduced cross-set breeding (0.001) to attempt to
diversify trial attempts.

Next objective - study the probabilities of progressive code
variations that might lead to improved results.

24/01/2025
Have adjusted the byte scoring to score zero for a hit and 255 for
a miss. Had an interesting result where I had changed the scoring
to give an idea of proximity to the correct result. The system used
this as a cheat to obtain the correct result!

Currently, I observe that what we are trying to achieve is to pluck 
the required results from a probability field, where we are uncertain
of the scale of the probabilities involved and therefore do not know
how much processing time is required.

From this standpoint it makes sense to put more effort into examining
probabilities, rather than measuring it empirically, which is what the
trials involve.

From the cheat result, we note that the system rapidly evolved a method
involving about 8 instructions, for solving scores in each problem
space. So we know empirically that we can achieve optimal solutions
that involve 8 instructions.

The trials thus far have proved that the system tends to evolve one
rational solution loop (transfer of input to output) and then a statistical
loop which scatters random numbers to the other problem spaces, some
of which incidentally score in those spaces. It does not yet evolve 
algorithms that are effective on the problem spaces.

21/01/2025
After about 30 million trials, the system tends to evolve two loops
which spread series through the output, with random score hits in
the output areas. There is no sign of algorithms to match specific
requirements from the inputs to the outputs.

The two loops tend to be of about 12 or 13 bytes in length (10 or 11
instructions). Also included is a termination condition in which 
multiple PUSH operations eventually break the end of the loop so
the program terminates in a string of NOOP operations.

As far as the system "works" it can be said to demonstrate increasing
sophistication. As far as finding specific solutions in finite time
we observe that it is not a practical solution.

So the next stage suggested is to increase the number of problems
set in the input space (since we have about 128 bytes remaining)
and allow the system to "explore" this space, coming-up with whatever
approaches it may evolve over a period of 10 to 20 days, if this
proves practical or desirable.

The things to watch-out for include getting trapped in particular 
solutions or whether the system continues to maintain sufficient
diversity to make steady score progress (albeit slow).

20/01/2025
The system quite rapidly resolves to a single solution - suggested
measures:

Increase the number of best sets to 48.

Decrease the frequency of cross-set breeding.

Increase the period between pass clearances.

Reaches 61 out of 146(max) over 60 million trials.


19/01/2025
Added score for reverse jump loops to encourage multiple score space
solutions.

Added routine to remove duplicate scores in the clearance pass.

After four hours have results of 57 versus 146 (max) just over
1/3. Will leave trial for about 18 or 20 hours.

Consider checking whether the loop back code is actually used as
well.

18/01/2025
Tried exponential scoring to see if it would produce specialisations,
instead no hits were scored at all against rules other than series,
different and params match.

Consider scores overlaying a single section of output.

16/01/2025
Introduced breeding from sections of code marked as used.

Flattened the scoring

Checked out simple seeding

Trial still produces scores of between a third and a half
after 20 million trials.

It is possible that seeding combined with the flagged
blocks interbreeding will improve matters. This is to
be the next trial. Accelerates development for a little
while, but soon hits the same plateau.

Reduce the the scores for the output only rules.

13/01/2025
Introduced staged rules

Introduced byte level mutations for monoclonal breeding as well as
instruction level.

Run to test byte level mutation underway. Staged rules made no appreciable
improvement over earlier attempts in a 10 hour, 16 million trial run.

The difficulty in the development of the entities remains the issue of
restricted probability pathways and the sheer fact of very low probabilities
of useful code arising.

Next stage, further the development of seed code/templates.

09/01/2025

Rulesets rearranged and added params -3. Increased number
of best sets to 32. 

Score still tends to settle at 1/3 or just below, scatterings
of random numbers and series.

Suggestions for work:

Localised interset breeding.

Paginated long range memory.
    256 byte pages referenced by 
        LDF A, (DC)
        LDF A, (MEM)
        STF (DC), A 
        STF (MEM), A 
        CFAR
        CFSM
        Additional reg D for 16 bit addresses

05/01/2025
All of the changes suggested were made, but the app still
plateaus at a score of about 1/3 of the maximum, presumably
because optima found at this level, do not provide a reasonably
high probability of finding an improvement. So we move back
to analysis to see what improvements might be made.

see WorkedExamples.txt

25/12/2024
Introduced a set of new instructions for the B and C registers.
Changed the number of best sets to 24 with just 40 entities in
each to overcome traps a bit better.
Increased the maximum instruction execution count to 2000 from 1000
to see whether the increased diversity would help.

Introduce a TSTO instruction which returns a 0-255 score in the A reg
for the last output value.

Consider introducing a rule for the adding together of adjacent
parameter inputs.

Consider including key words/symbols in the input data with examples,
ie: + a b, - a b, * a b, / a b
 
Meanwhile consider better strategies for code grouping.

13/12/2024
Tried increasing the number of best sets from 4 to 8. No particular
gain, progress slower, set back to 4.

Fixed problem with the instruction set (missing break; statements).

Ran an overnight run of about 48,000,000 trials. Little progress.
Try including memory transfers using register relative addressing.
This increases the size of the instruction set, so need to rework
the calculations accordingly.

Included the instructions ST A, (C) etc, for indexed addressing.
Initial gains large, but there appears to be a problem with breeding
methods, as gains are extremely slow after about 5 or 10 minutes.

11/12/2024
Multiple best sets included. Separated input output memory into
separate blocks of 256 bytes and included the relevant instructions
in the instruction set.

Achieved a 100% trial in 9 hours (20,000,000 trials), but it is rarely 
repeatable.

A great deal seems to depend on the initial selections, so will extend
the period of random generation per best set to several cycles.

07/12/2024
Having included the placing the outputs and parameters in
separate memory chunks and allowing for fixed block interbreeding
the scores to about 50% of the max in 45 minutes.

The next trial is to have separate best sets that interbreed with
each other periodically.

06/12/2024
The alternate input parameters approach improves matters only
slightly, the primary issue is that local optima are identified
by the system by simply placing (random) numbers in the output
rather than by the use of probabilities. This is because the
output sample sizes are small (4) so the chances of the random
numbers being on target can be higher than that of sequencers.

To overcome this, we can separate the parameter and output blocks
into separate chunks of 256 bytes and use different instructions
to access each.

04/12/2024
Having run the procedure for 5 hours (about 45,000,000 trials) a 
mediocre result was attained mostly consisting of random insertion
of numbers in the output fields.

Since the aim is to provide general operative functions, we need a
procedure to encourage this.

So let's try alternating the input parameters and using the same
rule set. The scoring can be done for each parameters set.

31/11/2024

Having managed to get as far as sequences of numbers in the top scoring position,
I decided to see if I could get more variant results by dividing up the ruleset
examinations of the output values into sections. The initial results are not
particularly promising although I may be able to compensate with counter-prevailing
rulesets (particularly a negative score for values of output left the same).

An option to consider is multiple best sets to overcome the problem of the
system getting trapped in probability dips arising from initial choices.

We may be able to distinguish in our trials between current selection scenarios
and those arising from ruleset weightings. The issue is to try to limit the
range of possible trial parameters.

At the present time the system is sticking with values still set to zero
in the output areas, let us try the rule that something is better than
nothing. If this rule is weighted at 100, it emerges as the prevalent
and produces a series on the output. What is more, variety is maintained
amongst the best set.

So if we now try upping the rating for multiply by two slightly, we maintain
the instability.

So we juggle the weights accordingly.
